# 📡 Airflow: Sensors

🔁 **Sensors wait** for a specific **event/condition** to be met before completing.

⏳ **Default Timeout:**  
Sensors will **timeout after 7 days** unless you set a custom value using the `timeout` parameter.

⏱️ **Polling Frequency:**  
Sensors check the condition **every `poke_interval`** (⏰ default: **60 seconds**).

💼 **Resource Usage:**  
While waiting, a sensor **holds a worker slot**, which can lead to resource contention if many are used.

🧘 **Use Reschedule Mode:**  
For long waits or many sensors, switch to `reschedule` mode:
- 🟡 Status: `up_for_reschedule`
- ✅ Frees up worker slots while waiting!

🔧 **Define with Decorator:**  
You can create a sensor using the `@task.sensor` decorator.

## 🧪 Example: File Sensor with Reschedule Mode

```python
from airflow.decorators import dag, task, task_sensor
from airflow.utils.dates import days_ago
import os

@dag(start_date=days_ago(1), schedule_interval=None, catchup=False)
def sensor_example_dag():

    @task_sensor(poke_interval=30, timeout=3600, mode="reschedule")
    def wait_for_file():
        filepath = "/tmp/data_ready.txt"
        return os.path.exists(filepath)

    @task
    def process_file():
        print("File found! Starting processing...")

    wait = wait_for_file()
    process_file() >> wait

sensor_example_dag()
```

🧾 Explanation:
- 🛠️ `@task_sensor`: Defines a sensor task using the decorator.
- ⏳ `timeout=3600`: Wait up to 1 hour for the file.
- ⏱️ `poke_interval=30`: Check every 30 seconds.
- 🧘 `mode="reschedule"`: Releases the worker slot while waiting.
- 📂 **Logic**: Waits until /tmp/data_ready.txt exists, then proceeds to the processing task.

